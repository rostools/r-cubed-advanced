# A general approach to doing statistical analyses {#sec-stats-analyses-basic}

```{r setup}
#| include: false
source(here::here("R/functions.R"))
extract_functions_from_qmd()
source(here::here("R/project-functions.R"))
library(tidyverse)
lipidomics <- read_csv(here::here("data/lipidomics.csv"))
num_metabolites <- nrow(count(lipidomics, metabolite))
```

Running analyses in R can be surprisingly simple, but things get
complicated when you want to run more models, different types of models,
do different types of data transformations, and extracting the results.
So using a general framework can simplify this process.

In this session we will break things down by first analysing our data
using one model so that in the next session we can apply what we've done
here to run many models at once.

## Learning objectives

{{< include /includes/objectives/_stats-analyses-basic.qmd >}}

Things we will *not* cover:

-   How to interpret the statistical results.

This workshop is not about specific statistical methods, using them
properly, nor interpreting them.

## :speech_balloon: Discussion activity: Brainstorming a potential design for the statistical analyses

**Time: \~18 minutes.**

As you learned in @sec-pipelines-setup, taking a step back and thinking
about, then sketching out a simple design for the flow of your data and
code can be extremely helpful. Breaking things down into smaller pieces
that you can build up together to produce a final output that you want
is a great approach to help you focus on what you actually need to write
before writing any code.

So, before we get into writing some code to run a statistical analysis,
take a few minutes to brainstorm and sketch out how a design might look
for running a statistical analysis and applying it in the `{targets}`
pipeline. Try to design each step or piece to have one or two inputs and
only one output. We'll return to designing the flow that we will use for
this workshop a bit later in the session, but we want you to try it
yourself now to get some practice with it, before we actually go through
it together.

Remember, there are always more ways of doing things that one, so what
we eventually use doesn't mean it is the only way or even the best way
(especially for your own work). *But, try not to look ahead anyway*
:stuck_out_tongue_closed_eyes:

1.  Take 6 minutes to individually brainstorm and sketch out how you
    think a statistical analysis workflow might look like, from input
    data to output results, and how that might fit into the `{targets}`
    pipeline. Design this workflow in a way that is flexible to changes
    (e.g. run one or many models on different metabolites). Try using
    pen and paper to draw out some boxes and arrows connecting the
    boxes. Review @fig-our-pipeline-design and @fig-build-table-flow to
    remind yourself of how we designed our previous targets.

2.  Take 6 minutes with your neighbour to share and discuss what you
    both have come up with. Try to come to a common understanding or
    agreement of how the design might be.

3.  Finally, over the last 6 minutes, you all can share some of your
    designs and we can discuss some potential benefits and drawbacks of
    different designs.

## Reviewing our research questions and models

::: {.callout-note collapse="true"}
## :teacher: Teacher note

Briefly show them this section, verbally reviewing the research
questions and then show the models that we'll use for those questions.
Reinforce that we are using the actual variable names from the data in
the formula.

Highlight that our data is in long format, so we will need to remember
that. Also highlight that we want to break things down to build
functions that work for one model and one metabolite, so that later we
can apply it to all of them.
:::

As we covered in @sec-stats-modeling, our research questions for this
workshop are simple but also allow us to showcase different coding
approaches and challenges. They are:

1.  What is the estimated relationship of each metabolite with type 1
    diabetes (T1D) compared to the controls?

2.  What is the estimated relationship after considering the influence
    of age and gender?

3.  How do the estimated relationships compare between metabolites?

Or mathematically for the simple model, but instead using the variable
name found in the data (`class` for T1D and `value` for the metabolite
value):

$$class = value$$

And for the more complex model:

$$class = value + age + gender$$

Right now, our data contains all metabolites in a single column, which
means our data doesn't match the requirement of our model: that there is
only one row per person. So we will need to do something to make sure
our model(s) only have the `value` for the specific metabolite we want
to model.

In our data set, we have `r num_metabolites` metabolites in our
`lipidomics` data. Combined with our two models we want to fit to each
metabolite, that is `r num_metabolites * 2` models to fit! When
designing and thinking about code in a functional programming way, if
you make something work for one thing, then it can work for all. So
we'll start by building functions that work for one metabolite and one
model. We'll start with the simple model first as well as use
`Cholesterol` as the metabolite to focus on.

## Designing the analysis workflow

What are some steps we could take, after what we learned in the previous
sessions? Let's start high level first, at the pipeline level. We'll use
a similar diagram as we used in @sec-pipelines-output, but instead focus
on just the modeling part.

```{mermaid}
%%| label: fig-stats-analysis-pipeline
%%| fig-cap: Targets in our pipeline for creating the statistical analysis outputs.
%%| echo: false
graph TB
    data_file["data_file<br>'data/lipidomics.csv'"]:::done -->|"read_csv()"| lipidomics:::done
    lipidomics -->|"create_model_results()"| model_results:::wip
    model_results -->|"plot_model_results()"| plot_model_results:::wip
    model_results -->|"tar_read()"| report:::wip
    plot_model_results -->|"tar_read()"| report:::wip
    classDef done stroke-width:3px
    classDef wip fill:#ffedd6
```

The first target we want to create is the `model_results` target, which
needs the `create_model_results()` function that we need to make. Let's
sketch out a diagram of what that function might do internally.

```{mermaid}
flowchart TB
    model["model:<br>class ~ value"]
    lipidomics --> transformed[Transformed]
    model & transformed --> fit_model[Fit model<br>to data]
    fit_model --> extract_results[Extract<br>results]
```

## Checking the data

Let's switch to working in the `doc/learning.qmd` file to create those
logistic regression models. In the `doc/learning.qmd` file, on the
bottom of the document create a new header and code chunk:

```` {.markdown filename="docs/learning.qmd"}
## Checking the data

```{{r}}

```
````

```{r too-many-cholesterols}
#| filename: "docs/learning.qmd"
lipidomics |>
  count(code, metabolite) |>
  filter(n > 1)
```

The second issue is that there seems to be a data entry error, since
there are multiple `Cholesterol` values, while all other metabolites
only have one:

To actually fix the multiple cholesterol issue, we should look more into
the data documentation or contact the authors. But for this workshop, we
will summarise all the metabolites by mean. In this case, only
Cholesterol will be summarised, all the rest values won't be impacted.
So we'll summarise only the `value` column by grouping by all but that
column, and use the `.groups = "keep"` argument to keep the grouping
variables since we want them. We have to use `pick()` in order to select
all columns except `value`.

```{r}
#| filename: "docs/learning.qmd"
lipidomics |>
  group_by(pick(-value)) |>
  summarise(value = mean(value), .groups = "keep") |>
  ungroup()
```

This issue impacts our other outputs, like the table and plot we made in
the last sessions. So this fix we have here needs to be applied near the
start of the pipeline. If we revise our diagram from before, focusing
only on the start of it, we want it to look like this now:

```{mermaid}
%%| label: fig-stats-analysis-pipeline2
%%| fig-cap: Targets in our pipeline that we've done in the last session and those we will do in this session.
%%| echo: false
graph TB
    data_file["data_file<br>'data/lipidomics.csv'"]:::done -->|"read_csv() |><br>clean()"| lipidomics:::done
    classDef done stroke-width:3px
    classDef wip fill:#ffedd6
```

So we want to create a function called `clean()` (or other similar name)
that we put in the pipeline that has this code to fix up issues in the
data. Let's make that function now:

```{r create-clean-function}
#| filename: "docs/learning.qmd"
clean <- function(data) {
  data |>
    dplyr::group_by(dplyr::pick(-value)) |>
    dplyr::summarise(value = mean(value), .groups = "keep") |>
    dplyr::ungroup()
}

clean(lipidomics)
```

We'll add the Roxygen documents now:

```{r roxygen-clean-function}
```

Move it into the `R/functions.R` file and run styler with
{{< var keybind.styler >}}. Then open the `_targets.R` file and revise
the `lipidomics` target to use the `clean()` function:

```{r}
#| eval: false
#| filename: "_targets.R"
list(
  ...,
  tar_target(
    name = lipidomics,
    command = read_csv(here::here("data/lipidomics.csv")) |>
      clean()
  ),
  ...
)
```

Then run `targets::tar_visnetwork()` using
{{< var keybind.targets-vis >}} to see if the new target gets detected.
If it does, than run `targets::tar_make()` with
{{< var keybind.targets-make >}}.

Go back to the `docs/learning.qmd` file, restart R with
{{< var keybind.restart-r >}} and then go to the bottom of the file and
add a new code chunk.

Since we're trying to build up functions to analyse *one model* first,
we'll start with filtering for one metabolite and using a simple model.
We'll use cholesterol again since it's easy to remember and the model
will be `class ~ value` (the metabolite's `value` and T1D).

```{r}
#| purl: true
#| echo: false
lipidomics <- clean(lipidomics)
```

```{r}
lipidomics |>
  filter(metabolite == "Cholesterol") |>
  mutate(
    class = as.factor(class),
    value = scale(value)
  )
```

```{r}
glm(
  formula = class ~ value + age + gender,
  data = lipidomics,
  family = binomial
) |>
  broom::tidy(exponentiate = TRUE)

model <- class ~ value + age + gender

glm(
  data = lipidomics,
  formula = model,
  family = binomial
) |>
  broom::tidy(exponentiate = TRUE) |>
  dplyr::mutate(model = format(model))
```

```{r}
preprocess <- function(data) {
  data |>
    mutate(
      class = as.factor(class),
      value = scale(value)
    )
}

fit_model <- function(data, model) {
  glm(
    formula = model,
    data = data,
    family = binomial
  ) |>
    broom::tidy(exponentiate = TRUE) |>
    # Converts ("formats") the formula to a string.
    dplyr::mutate(
      metabolite = unique(data$metabolite),
      model = format(model),
      .before = tidyselect::everything()
    )
}

lipidomics |>
  clean() |>
  filter(metabolite == "Cholesterol") |>
  preprocess() |>
  fit_model(class ~ value)

create_model_results <- function(data) {
  model <- class ~ value
  data |>
    preprocess() |>
    fit_model(model)
}

lipidomics |>
  clean() |>
  filter(metabolite == "Cholesterol") |>
  create_model_results()
```

(As exercise?)

```{r}
#| filename: Console
lipidomics
```

The first issue, which isn't always an issue, depends heavily on the
model type you use. Since we are using logistic regression, the model
assumes that each row is an individual person. But our data is in the
long format, so each person has multiple rows per metabolite. But let's
confirm if each person has one value per metabolite:

## Pre-processing before modeling

::: {.callout-note collapse="true"}
## :teacher: Instructor note

Verbally talk through the next few paragraphs, no code-along yet.
:::

How to make the results between metabolites comparable.

Each metabolite has quite large differences in the values and ranges of
data. Again, whether this is an issue depends on what we want to do, but
in our research question we want to know how each metabolite influences
T1D. In order to best interpret the results and compare across
metabolites, we should ideally have all the metabolites with a similar
range and distribution of values.

There are many transformations we could use for the `lipidomics`
dataset, but we will use normalization (which is a combination of
mean-centering and scaling) for this workshop. This is useful because it
makes each variable centered to zero at the mean and a value of 1 unit
is translated to 1 standard deviation of the original distribution. This
means we can more easily compare values between variables.

Style using {{< var keybind.styler >}}, then commit the changes made to
the Git history with {{< var keybind.git >}}.

## Fitting the model to the data {#sec-fitting-model}

We've now defined the model we want to use and transformed the data. Now
we can start putting them together and finally fit them to the data.

To get this information in a tidier format, we use another function:
`tidy()`. This function comes from the `{broom}` package. But we should
explicitly add it to the dependencies:

```{r broom-to-deps}
#| purl: true
#| eval: false
#| filename: Console
use_package("broom")
```

Then, we add the `tidy()` function to our model using the `|>` pipe.
Since we are using a logistic regression model, we need to consider how
we want the estimates to be presented, probably depending on how we want
to visualize our results. If we set `exponentiate = TRUE` in `tidy()`,
the output estimates will be odds ratios, if we set
`exponentiate = FALSE`, we will get the log odds ratios. Here we choose
`exponentiate = TRUE`:

```{r tidy-up-model-results}
#| filename: "docs/learning.qmd"
#| eval: false
fitted_model |>
  broom::tidy(exponentiate = TRUE)
```

We now have a data frame of our model results!

::: {.callout-note collapse="true"}
## :teacher: Instructor note

Reinforce **not** to worry about interpreting the results, that is not
the aim of this workshop.
:::

::: callout-important
Another reminder, we **are not** interpreting this results. For this
workshop, they are **not** important and can distract from the main
purpose.
:::

Let's briefly cover what these columns and values mean. But first, open
the Git interface and commit the changes you made with
{{< var keybind.git >}}. Then push your changes up to GitHub.

::: {.callout-note collapse="true"}
## :teacher: Instructor note

If you want, you can go over these details briefly or in more detail,
depending on how comfortable you are. Or you can get them to read it
only.
:::

## :technologist: Exercise: Add a target for the model results

**Time: \~8 minutes.**

Taking the function code from above, you'll next add the model results
output to end of the `_targets.R` file, using the below scaffold as a
guide.

``` r
list(
  ...,
  tar_target(
    name = ___,
    command = ___(___)
  )
)
```

1.  Use `df_model_estimates` for the `name`.
2.  Use the `calculate_estimates()` function in `command`, with
    `lipidomics` as the argument.
3.  Use {{< var keybind.styler >}} to style and than run
    `targets::tar_visnetwork()` using {{< var keybind.targets-vis >}} to
    see if the new target gets detected. If it does, than run
    `targets::tar_make()` with {{< var keybind.targets-make >}}.
4.  Commit the changes to the Git history with {{< var keybind.git >}}.

```{r solution-target-model-estimates}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
list(
  # ...,
  tar_target(
    name = df_model_estimates,
    command = calculate_estimates(lipidomics)
  )
)
```

```{r purl-only-model-estimates-to-targets}
#| eval: false
#| echo: false
#| purl: true
update_target_calc_est <- "
  ),
  list(
    name = df_model_estimates,
    command = calculate_estimates(lipidomics)
  )
)
"
# print_lines("_targets.R")
revise_by_line_num(
  path = "_targets.R",
  insert_text = update_target_calc_est,
  # Modify these numbers.
  remove_original_lines = -30,
  insert_at_line = 31
)
targets::tar_visnetwork()
targets::tar_make()
git_ci("_targets.R", "Update targets with model results")
```

{{< text_snippet sticky_up >}}

## :book: Reading task: Understanding the model output

**Time: \~10 minutes.**

Let's explain this output a bit, each column at a time:

-   `term`: If you recall the formula
    $class = metabolite + age + gender$, you'll see all but the `class`
    object there in the column `term`. This column contains all the
    predictor variables, including the intercept (from the original
    model).

-   `estimate`: This column is the "coefficient" linked to the term in
    the model. The final mathematical model here looks like:

    $$ \displaylines{class = Intercept + (metabolite\_estimate \times metabolite\_value) + \\ (gender\_estimate \times gender\_value) + ...}$$

    In our example, we chose to get the odds ratios. In the mathematical
    model above, the estimate is represented as the log odds ratio or
    beta coefficient - the constant value you multiply the value of the
    term with. Interpreting each of these values can be quite tricky and
    can take a surprising amount of time to conceptually break down, so
    we won't do that here, since this isn't a statistics workshop. The
    only thing you need to understand here is that the `estimate` is the
    value that tells us the *magnitude* of association between the term
    and `class`. This value, along with the `std.error` are the most
    important values we can get from the model and we will be using them
    when presenting the results.

-   `std.error`: This is the uncertainty in the `estimate` value. A
    higher value means there is less certainty in the value of the
    `estimate`.

-   `statistic`: This value is used to, essentially, calculate the
    `p.value`.

-   `p.value`: This is the infamous value we researchers go crazy for
    and think nothing else of. While there is a lot of attention to this
    single value, we tend to give it more attention than warranted. The
    interpretation of the p-value is even more difficult than the
    `estimate` and again, we won't cover this in this workshop. We won't
    be using this value at all in presenting the results.

{{< text_snippet sticky_up >}}

## Summary

-   Create research questions that (ideally) are structured in a way to
    mimic how the statistical analysis will be done, preferably in a
    "formula" style like $y = x1 + x2 + ... + error$ and in a diagram
    style with links connecting variables.
-   Statistical analyses, while requiring some trial and error, are
    surprisingly structured in the workflow and steps taken. Use this
    structure to help guide you in completing tasks related to running
    analyses.
-   Use `{broom}` to `tidy()` the model output, extracted using
    `extract_fit_parsnip()` to get a data frame of the estimates and
    standard error for the variables in the model.

{{< include /includes/_code-appendix.qmd >}}
