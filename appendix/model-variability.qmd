# Assessing variability

<!-- NOTE: This isn't included in the website right now -->

```{r setup}
#| include: false
source(here::here("R/functions.R"))
```

Connected to the concept of functional programming, is the idea of
resampling a dataset multiple times and running the statistical analysis
on each resampled set to calculate a more accurate measure of
uncertainty. We often use generic calculations of uncertainty like the
standard error or the confidence interval. Those are useful measures
especially with very large datasets, however, they have limitations of
their own. By making use of resampling, we can identify how uncertain or
unreliable a statistical result might be for our specific dataset. This
session will be about learning and applying other methods of determining
uncertainty through the use of functional programming.

## Learning objectives

1.  Describe what a resampling technique is, the types available, and
    why it can help estimate the variability of model results. Apply
    functions from `{rsample}` and `{tune}` to use these techniques.

## Determine variability in model estimates with resampling

Depending on the type of research questions, there are several ways to
assess variability (or uncertainty) in the model results. We could use
the calculated standard error of the estimate or calculate the
confidence interval from the standard error (using
`tidy(conf.int = TRUE)`). The disadvantage of this approach is that it
isn't very accurate for the data. Plus, when we have such small sample
sizes, some issues can limit the use of these typical measures of
uncertainty. And we've already noticed that there is something strange
with the estimates for some of the metabolites.

So instead, we can use something that is a bit more targeted to the data
called "resampling". There are many resampling techniques, and they all
have slightly different uses. The one we will use is called the
["bootstrap"](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))[^model-variability-1].
What bootstrapping does is take the data and randomly resamples it as
many times as there are rows. This means you can potentially resample
*the same data (in our case, person) more than once* (called "with
replacement"). So by pure chance, you could theoretically have a
"resampled set" from `lipidomics` where all 36 rows are only duplicate
data on one person!

[^model-variability-1]: Another common technique is called ["v-fold
    cross-validation"](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation),
    which provides a way of assessing how well the model as a whole
    performs at fitting the data, rather than bootstrap which determines
    how varied the estimate can be.

<!-- TODO: Make a diagram of this at some point. -->

What's the advantage of this? It is a way of directly calculating the
standard error from the data itself (rather than from a formula), so it
gives a more accurate view of how uncertain the model estimate is for
our data. Usually, creating between 50 to 100 "resampled sets" is
sufficient to calculate a value for the variation. Because running
models with bootstrapped sets can take a long time to process, we will
only resample 10 times, or less if your computer is slow.

We're using the `{rsamples}` package to handle "resampling". So let's
add it to our dependency list:

```{r rsamples-to-deps}
#| purl: true
#| eval: false
use_package("rsamples")
```

We will eventually run bootstraps on all the metabolites, so we will
need to use our `split_by_metabolite()` function first. For now, we will
only use the first item in that list (accessed with `[[1]]`) to show
that the code works without running on all the metabolites every time.
Create another code chunk at the bottom of `doc/learning.qmd` to add
this code:

```{r split-metabolite-for-bootstrap}
lipidomics_list <- lipidomics |>
  split_by_metabolite()
```

::: callout-note
## :book: Reading task: \~10 minutes

> *You don't need to run the code in this reading section*.

The `bootstraps()` function is how we create resampled sets. Since this
is done randomly, we should use `set.seed()` in order for the analysis
to be reproducible. Nothing is truly random in computers, and instead is
actually "pseudorandom". In order for our analysis to be reproducible,
we use `set.seed()` to force a specific "pseudorandom" value.

```{r show-bootstrap-first-item}
set.seed(1324)
bootstraps(lipidomics_list[[1]], times = 10)
```

This output is called a "nested tibble". A nested tibble is a
tibble/data frame where one or more of the columns are actually a list
object. In our case, each bootstrapped set (marked by the `id`) has
instructions on how the resampled data will look. We can see what it
looks like by accessing the `splits` column and looking at the first
item with `[[1]]`:

```{r show-split-contents}
bootstraps(lipidomics_list[[1]], times = 10)$splits[[1]]
```

The contents of this resampled set are split into "analysis" sets and
"assessment" sets. You don't need to worry about what these mean or how
to use them, since a function we will later use handles it for us. But
to give you an idea of what bootstrapping is doing here, we can access
one of the sets with either the `analysis()` or `assessment()`
functions. We'll `arrange()` by `code` to show how we can have duplicate
persons when resampling:

```{r show-split-contents-analysis}
bootstraps(lipidomics_list[[1]], times = 10)$splits[[1]] |>
  analysis() |>
  arrange(code)
```

See how some `code` IDs are the same? Those are the same person that has
been selected randomly into this resampled set.
:::

Like we did with the previous modeling, we need to create a workflow
object. We'll use the first metabolite (`lipidomics_list[[1]]`) for now,
but will revise the code to eventually run the bootstrapping on all
metabolites.

```{r create-workflow-for-bootstrap}
workflow_for_bootstrap <- create_model_workflow(
  logistic_reg() |>
    set_engine("glm"),
  lipidomics_list[[1]] |>
    create_recipe_spec(starts_with("metabolite_"))
)
```

Previously, we used `fit()` on the workflow and on the data. Instead, we
will use `fit_resamples()` to run the model on the bootstrapped data.
Instead of the `data` argument in `fit()`, it is the `resamples`
argument where we provide the `bootstraps()` sets. We could run the code
with only the workflow object and the resampled data, but there's an
extra argument in `fit_resamples()` that controls some actions taken
during the fitting by using the `control_resamples()` function. For
instance, we can save the predictions with `save_pred = TRUE` and we can
process the output with our `tidy_model_output()` function in the
`extract` argument. So let's do that. First, both `fit_resamples()` and
`control_resamples()` come from the `{tune}` package, so let's add it to
the dependencies first.

```{r tune-to-deps}
#| purl: true
#| eval: false
use_package("tune")
```

Now, we can write the code for `fit_resamples()` on the `bootstraps()`
of the first item in the `lipidomics_list` and setting the `control`
options with `control_resamples()`.

```{r fit-on-resampled-sets}
bootstrapped_results <- fit_resamples(
  workflow_for_bootstrap,
  resamples = bootstraps(lipidomics_list[[1]], times = 10),
  control = control_resamples(
    extract = tidy_model_output,
    save_pred = TRUE
  )
)
bootstrapped_results
```

You'll see that it gives another nested tibble, but with more columns
included. Before we start selecting the results that we want, let's
convert the code above into a function, using the function-oriented
workflow we've used throughout the course.

```{r new-function-generate-model-variation}
#' Generate the model variation results using bootstrap on a single metabolite.
#'
#' @param data The lipidomics data.
#'
#' @return A nested tibble.
#'
generate_model_variation <- function(data) {
  create_model_workflow(
    parsnip::logistic_reg() |>
      parsnip::set_engine("glm"),
    data |>
      create_recipe_spec(tidyselect::starts_with("metabolite_"))
  ) |>
    tune::fit_resamples(
      resamples = rsample::bootstraps(data, times = 10),
      control = tune::control_resamples(
        extract = tidy_model_output,
        save_pred = TRUE
      )
    )
}
```

Re-writing the code to use the function, it becomes:

```{r use-generate-variation-function}
bootstrapped_results <- lipidomics_list[[1]] |>
  generate_model_variation()
bootstrapped_results
```

Let's explain this output a bit. The `fit_resamples()` function outputs
a nested tibble, where each row is a resampled set. The columns that
begin with `.` (`.metrics` or `.extracts`) are extracted details from
each model fit to the resampled set. We'll ignore all but the
`.extracts` column, since that is the column that we set to extract the
`tidy_model_output()`. Let's `select()` only the `id` and the
`.extracts` column and use `unnest()` to convert the nested tibble to a
regular tibble based on the column given.

```{r unnext-extracts}
bootstrapped_results |>
  select(id, .extracts) |>
  unnest(cols = .extracts)
```

Alright, this is actually another nested tibble (we can see based on the
new column `.extracts` where each row is called a `<tibble>`). So let's
again `unnest()` this new `.extracts` column.

```{r unnest-unnest-bootstrap}
bootstrapped_results |>
  select(id, .extracts) |>
  unnest(cols = .extracts) |>
  unnest(cols = .extracts)
```

Now this is something we are familiar with looking at! It shows the
`term`, the `estimate`, as well as the bootstrap `id`. Like before, we
only want the metabolite `estimate`, so we can use `filter()` and
`str_detect()` like last time, as well as add the original variable
names with `add_original_metabolite_names()`.

```{r unnest-unnest-tidy-bootstrap-results}
bootstrapped_results |>
  select(id, .extracts) |>
  unnest(cols = .extracts) |>
  unnest(cols = .extracts) |>
  filter(str_detect(term, "metabolite_")) |>
  add_original_metabolite_names(lipidomics)
```

Using the same workflow as before, let's convert this into a function:

```{r new-function-tidy-bootstrap-output}
#' Tidy up the bootstrap output.
#'
#' @param bootstrap_results The bootstrap object with model results.
#'
#' @return A data frame.
#'
tidy_bootstrap_output <- function(bootstrap_results) {
  bootstrap_results |>
    dplyr::select(id, .extracts) |>
    # Need to unnest twice since first `.extracts` is a nest of another two
    # columns of `.extracts` and `.config`.
    tidyr::unnest(cols = .extracts) |>
    tidyr::unnest(cols = .extracts) |>
    dplyr::filter(stringr::str_detect(term, "metabolite_")) |>
    add_original_metabolite_names(lipidomics)
}
```

Then we can start from the beginning again, right from `lipidomics`, to
`split_by_metabolite()`, to `map()`'ing with
`generate_model_variation()`, and finally to `map()` and `list_rbind()`
with `tidy_bootstrap_output()`. Keep in mind, this will take a while to
run.

```{r chain-data-to-bootstrap-results}
#| eval: false
metabolites_with_bootstrap_results <- lipidomics |>
  split_by_metabolite() |>
  map(generate_model_variation) |>
  map(tidy_bootstrap_output) |> 
  list_rbind()
metabolites_with_bootstrap_results
```

```{r exec-only-show-bootstrap-results}
#| echo: false
metabolites_with_bootstrap_results
```

## :technologist: Exercise: Convert to function and add as a target in the pipeline

> Time: \~15 minutes.

Continue the workflow we've applied throughout the course:

1.  Move the code into a function structure (use the scaffold below as a
    guide).
2.  Include one argument in the `function()` called `data`.
3.  Replace `lipidomics` in the code with `data`.
4.  Add the Roxygen documentation with {{< var keybind.roxgyen >}}.
5.  Cut and paste the function over into the `R/functions.R` file.
6.  Style using {{< var keybind.styler >}}.
7.  Commit the changes to the Git history with {{< var keybind.git >}}.

Use this code as a guide for the function.

``` r
calculate_variation <- function(___) {
  ___ |> 
    # Code from above.
    ___
}
```

```{r solution-new-function-calculate-variation}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
#' Calculate the uncertainty in results.
#'
#' @param data The lipidomics data.
#'
#' @return A data frame (or file path)
#'
calculate_variation <- function(data) {
  data |>
    split_by_metabolite() |>
    purrr::map(generate_model_variation) |>
    purrr::map(tidy_bootstrap_output) |> 
    purrr::list_rbind()
}
```

Next, add the function to `_targets.R`.

1.  Create another `tar_target()` item in the `list()` at the bottom of
    the file.
2.  Use `df_model_variation` as the `name` and `calculate_variation()`
    as the `command` with `lipidomics` as argument.
3.  Run `targets::tar_visnetwork()` using
    {{< var keybind.targets-vis >}} to see what targets are outdated and
    then run `targets::tar_make()` with
    {{< var keybind.targets-make >}}.
4.  Commit the changes to the Git history with {{< var keybind.git >}}.

Use this code as a scaffold:

``` r
list(
  ...,
  tar_target(
    name = ___,
    command = ___
  )
)
```

```{r purl-only-variation-to-targets}
#| eval: false
#| echo: false
#| purl: true
variation_targets_code <- '
  ),
  tar_target(
    name = df_model_variation,
    command = calculate_variation(lipidomics)
  )
)
'
# print_lines("_targets.R")
revise_by_line_num(
  path = "_targets.R",
  insert_text = variation_targets_code,
  # Modify these numbers.
  remove_original_lines = -30,
  insert_at_line = 31
)
targets::tar_visnetwork()
targets::tar_make()
git_ci("_targets.R", "Update targets with model variation")
```

```{r solution-calculate-variation-to-pipeline}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
list(
  # ...,
  tar_target(
    name = df_model_variation,
    command = calculate_variation(lipidomics)
  )
)
```

## Visualizing the variability of results

::: {.callout-note collapse="true"}
## :teacher: Instructor note

Take your time explaining why we might use a figure like this, and what
you're trying to show. Since there isn't much code involved, there is
time to explain.
:::

Like we did with the estimates, let's visualize the results. Visualizing
the estimates was pretty easy, visualizing the variation is even easier.
We want to show the range of `estimate` values across all the
bootstrapped models, by `metabolite` variable. There's a neat geom in
`{ggplot2}` called `geom_dotplot()` that is similar to a histogram, but
instead shows individual data points instead of bars. And since we want
to show the variation by `metabolite`, we can use `facet_wrap()`. We
will use `scales = "free"` because the range of values for `estimate`
are different for each `metabolite`.

```{r plot-variation}
metabolites_with_bootstrap_results |>
  ggplot(aes(x = estimate)) +
  geom_dotplot() +
  facet_wrap(vars(metabolite), scales = "free")
```

This nicely shows the ranges of values in the `estimate`, really
highlighting how uncertain the results are for answering our original
research questions. This figure could also be improved quite a bit from
a visual and aesthetic point of view, but at least from a content point
of view, it shows what we want. For now, we'll stick with this and
finish our last pipeline target before putting everything into the
`doc/learning.qmd` file.

Let's use our function workflow with this code:

1.  Create the code as a function, add a `data` argument, and replace
    the input data object name with `data`.
2.  Move the code into the `R/functions.R` file.
3.  Add the Roxygen documentation using {{< var keybind.roxygen >}} and
    fill it in.
4.  Style the code using {{< var keybind.styler >}}.

```{r new-function-plot-variation}
#' Plot the uncertainty in the estimates of the models.
#'
#' @param model_results The model results with the variation.
#'
#' @return A ggplot2 image.
#'
plot_variation <- function(model_results) {
  model_results |>
    ggplot2::ggplot(ggplot2::aes(x = estimate)) +
    ggplot2::geom_dotplot() +
    ggplot2::facet_wrap(ggplot2::vars(metabolite), scales = "free")
}
```

Then we'll add it as a pipeline target to the `_targets.R` file.

``` r
list(
  ...,
  tar_target(
    name = fig_model_variation,
    command = plot_variation(df_model_variation)
  )
)
```

Run `targets::tar_visnetwork()` using {{< var keybind.targets-vis >}}
and then run `targets::tar_make()` with
{{< var keybind.targets-make >}}. Once everything has been built, commit
everything to the Git history with {{< var keybind.git >}}.

## Summary

-   Use resampling techniques like `bootstraps()`, combined with
    `fit_resamples()`, to calculate measures of variation specific to
    the data. Combine with functionals like `map()` to run large numbers
    of models, easily and with minimal code.
-   Visualize variation in data with alternatives to histograms like
    `geom_dotplot()`.
